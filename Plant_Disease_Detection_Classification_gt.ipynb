{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oirfISxsQC1R",
        "outputId": "936e1e8c-03c3-4f7e-9e44-a6ec339a626b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3h-GdRkUkxn"
      },
      "source": [
        "root_path='gdrive/My Drive/PLANT DISEASE DETECTION/'\n",
        "# Proj Drive Folder\n",
        "# use print(root_path) / !ls proj_folder_path  to check"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57XorfM-Weuc"
      },
      "source": [
        "# from google.colab import files\n",
        "# files.upload()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUfMDsMeXMjv",
        "outputId": "3949910a-0995-4eec-e09a-f98a46934098"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json  # set permission"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe2QBkKLXTTC"
      },
      "source": [
        "# !kaggle datasets download -d koheidozono/newplantvillage -p '/content/gdrive/My Drive/PLANT DISEASE DETECTION/'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQUhPIU2fg4t"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k9VWXIegCfm",
        "outputId": "f715ba2e-1b3f-4ed2-8a23-263c11401c94"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/gdrive/MyDrive/PLANT DISEASE DETECTION/newplantvillage.zip', 'r') as zipObj:\n",
        "  zipObj.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NttA86B8rEte"
      },
      "source": [
        "classes_train = sorted(list(filter(lambda x: os.path.isdir('/content/newplantvillage/' + x), os.listdir('/content/newplantvillage'))))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuWR5kFcrYcP",
        "outputId": "c9dcb39e-2280-4791-e1ca-cbc9631c658d"
      },
      "source": [
        "print(classes_train) #to show names of all classes"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy', 'Healthy_leaf', 'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch', 'Strawberry___healthy', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVUPQaQBrzzV",
        "outputId": "7f212bf0-04b8-4909-f241-fcc7c43f54b1"
      },
      "source": [
        "!pip install split_folders"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split_folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split_folders\n",
            "Successfully installed split_folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V5ZQwOvsCQR",
        "outputId": "1b3928ed-99f1-4870-a875-aa8fecbca194"
      },
      "source": [
        "import splitfolders\n",
        "input_folder='/content/newplantvillage'\n",
        "splitfolders.ratio(input_folder, output=\"output\", seed=1337, ratio=(.8,.2)) #default values\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 63987 files [00:45, 1417.89 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dXXrnBCtLBr",
        "outputId": "a72f4c99-b394-4c1f-d675-1d138aef6986"
      },
      "source": [
        "batch_size=128\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen=ImageDataGenerator(rescale=1/255)\n",
        "train_generator=train_datagen.flow_from_directory(\n",
        "    '/content/output/train',\n",
        "    target_size=(200, 200),\n",
        "    batch_size=batch_size,\n",
        "    classes = classes_train,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "val_datagen=ImageDataGenerator(rescale=1/255)\n",
        "val_generator=val_datagen.flow_from_directory(\n",
        "    '/content/output/val',\n",
        "    target_size=(200, 200),\n",
        "    batch_size=batch_size,\n",
        "    classes = classes_train,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51174 images belonging to 35 classes.\n",
            "Found 12813 images belonging to 35 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of images per class in the training set\n",
        "train_class_counts = train_generator.classes\n",
        "train_class_counts_dict = {class_label: (train_class_counts == idx).sum()\n",
        "                           for class_label, idx in train_generator.class_indices.items()}\n",
        "print(\"Training set image counts per class:\")\n",
        "print(train_class_counts_dict)\n",
        "\n",
        "# Number of images per class in the validation set\n",
        "val_class_counts = val_generator.classes\n",
        "val_class_counts_dict = {class_label: (val_class_counts == idx).sum()\n",
        "                         for class_label, idx in val_generator.class_indices.items()}\n",
        "print(\"Validation set image counts per class:\")\n",
        "print(val_class_counts_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWBVzN-L-xgH",
        "outputId": "d202ed37-1407-4f07-8607-8895156c5dff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set image counts per class:\n",
            "{'Apple___Apple_scab': 1612, 'Apple___Black_rot': 1589, 'Apple___Cedar_apple_rust': 1408, 'Apple___healthy': 1606, 'Blueberry___healthy': 1452, 'Cherry_(including_sour)___Powdery_mildew': 1346, 'Cherry_(including_sour)___healthy': 1460, 'Grape___Black_rot': 1510, 'Grape___Esca_(Black_Measles)': 1536, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 1377, 'Grape___healthy': 1353, 'Healthy_leaf': 806, 'Orange___Haunglongbing_(Citrus_greening)': 1608, 'Peach___Bacterial_spot': 1470, 'Peach___healthy': 1382, 'Pepper,_bell___Bacterial_spot': 1530, 'Pepper,_bell___healthy': 1590, 'Potato___Early_blight': 1551, 'Potato___Late_blight': 1551, 'Potato___healthy': 1459, 'Raspberry___healthy': 1424, 'Soybean___healthy': 1617, 'Squash___Powdery_mildew': 1388, 'Strawberry___Leaf_scorch': 1419, 'Strawberry___healthy': 1459, 'Tomato___Bacterial_spot': 1361, 'Tomato___Early_blight': 1536, 'Tomato___Late_blight': 1480, 'Tomato___Leaf_Mold': 1505, 'Tomato___Septoria_leaf_spot': 1396, 'Tomato___Spider_mites Two-spotted_spider_mite': 1392, 'Tomato___Target_Spot': 1461, 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 1568, 'Tomato___Tomato_mosaic_virus': 1432, 'Tomato___healthy': 1540}\n",
            "Validation set image counts per class:\n",
            "{'Apple___Apple_scab': 404, 'Apple___Black_rot': 398, 'Apple___Cedar_apple_rust': 352, 'Apple___healthy': 402, 'Blueberry___healthy': 364, 'Cherry_(including_sour)___Powdery_mildew': 337, 'Cherry_(including_sour)___healthy': 366, 'Grape___Black_rot': 378, 'Grape___Esca_(Black_Measles)': 384, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 345, 'Grape___healthy': 339, 'Healthy_leaf': 202, 'Orange___Haunglongbing_(Citrus_greening)': 402, 'Peach___Bacterial_spot': 368, 'Peach___healthy': 346, 'Pepper,_bell___Bacterial_spot': 383, 'Pepper,_bell___healthy': 398, 'Potato___Early_blight': 388, 'Potato___Late_blight': 388, 'Potato___healthy': 365, 'Raspberry___healthy': 357, 'Soybean___healthy': 405, 'Squash___Powdery_mildew': 348, 'Strawberry___Leaf_scorch': 355, 'Strawberry___healthy': 365, 'Tomato___Bacterial_spot': 341, 'Tomato___Early_blight': 384, 'Tomato___Late_blight': 371, 'Tomato___Leaf_Mold': 377, 'Tomato___Septoria_leaf_spot': 349, 'Tomato___Spider_mites Two-spotted_spider_mite': 349, 'Tomato___Target_Spot': 366, 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 393, 'Tomato___Tomato_mosaic_virus': 358, 'Tomato___healthy': 386}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to display one image per class\n",
        "def display_one_image_per_class(generator, class_indices):\n",
        "    # Reverse the class indices dictionary to map index to class\n",
        "    index_to_class = {v: k for k, v in class_indices.items()}\n",
        "\n",
        "    # Dictionary to store one image per class\n",
        "    images_per_class = {class_name: None for class_name in class_indices}\n",
        "\n",
        "    # Iterate over the generator to find one image per class\n",
        "    for _ in range(len(generator)):\n",
        "        images, labels = next(generator)\n",
        "\n",
        "        for i in range(images.shape[0]):\n",
        "            class_index = np.argmax(labels[i])\n",
        "            class_name = index_to_class[class_index]\n",
        "\n",
        "            if images_per_class[class_name] is None:\n",
        "                images_per_class[class_name] = images[i]\n",
        "\n",
        "        # Break the loop if we have found an image for each class\n",
        "        if all(img is not None for img in images_per_class.values()):\n",
        "            break\n",
        "\n",
        "    # Prepare a figure to plot the images\n",
        "    plt.figure(figsize=(20, 25))\n",
        "\n",
        "    for idx, (class_name, img) in enumerate(images_per_class.items()):\n",
        "        plt.subplot(1, len(class_indices), idx + 1)\n",
        "        plt.imshow(img)\n",
        "        # plt.title(class_name)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Display one image per class in the training set\n",
        "display_one_image_per_class(train_generator, train_generator.class_indices)\n"
      ],
      "metadata": {
        "id": "5p6s-rZ0_IWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # The first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(200, 200, 3)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fifth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a dense layer\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 128 neuron in the fully-connected layer\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    # 35 output neurons for 35 classes with the softmax activation\n",
        "    tf.keras.layers.Dense(35, activation='softmax')\n",
        "])\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbZhs1R71cWE",
        "outputId": "d80eb036-3f69-49ce-9e8d-f392906fde8a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 198, 198, 16)      448       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 198, 198, 16)      64        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 99, 99, 16)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 97, 97, 32)        4640      \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 97, 97, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 48, 48, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 46, 46, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 46, 46, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 23, 23, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 21, 21, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 21, 21, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 10, 10, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 8, 8, 64)          256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 4, 4, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               131200    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 35)                4515      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 234115 (914.51 KB)\n",
            "Trainable params: 233635 (912.64 KB)\n",
            "Non-trainable params: 480 (1.88 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow import keras\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0005), metrics=['accuracy'])\n",
        "\n",
        "epochs=12\n",
        "steps_per_epoch=train_generator.n//train_generator.batch_size\n",
        "validation_steps=val_generator.n//val_generator.batch_size\n",
        "\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(\"/content/abc.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n",
        "\n",
        "history=model.fit(\n",
        "    x=train_generator,\n",
        "    y=None,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjFrjwmQWpOx",
        "outputId": "f6627983-5bb5-4dc1-c21b-caede7c8e949"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "399/399 [==============================] - ETA: 0s - loss: 0.8641 - accuracy: 0.7392\n",
            "Epoch 1: val_loss improved from inf to 5.99998, saving model to /content/abc.h5\n",
            "399/399 [==============================] - 332s 819ms/step - loss: 0.8641 - accuracy: 0.7392 - val_loss: 6.0000 - val_accuracy: 0.1587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/12\n",
            "399/399 [==============================] - ETA: 0s - loss: 0.2625 - accuracy: 0.9155\n",
            "Epoch 2: val_loss improved from 5.99998 to 0.42928, saving model to /content/abc.h5\n",
            "399/399 [==============================] - 263s 660ms/step - loss: 0.2625 - accuracy: 0.9155 - val_loss: 0.4293 - val_accuracy: 0.8606\n",
            "Epoch 3/12\n",
            "399/399 [==============================] - ETA: 0s - loss: 0.1469 - accuracy: 0.9514\n",
            "Epoch 3: val_loss did not improve from 0.42928\n",
            "399/399 [==============================] - 315s 789ms/step - loss: 0.1469 - accuracy: 0.9514 - val_loss: 0.5706 - val_accuracy: 0.8366\n",
            "Epoch 4/12\n",
            "399/399 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 0.9662\n",
            "Epoch 4: val_loss improved from 0.42928 to 0.19909, saving model to /content/abc.h5\n",
            "399/399 [==============================] - 301s 754ms/step - loss: 0.0994 - accuracy: 0.9662 - val_loss: 0.1991 - val_accuracy: 0.9383\n",
            "Epoch 5/12\n",
            "399/399 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9742\n",
            "Epoch 5: val_loss did not improve from 0.19909\n",
            "399/399 [==============================] - 287s 720ms/step - loss: 0.0745 - accuracy: 0.9742 - val_loss: 0.6180 - val_accuracy: 0.8546\n",
            "Epoch 6/12\n",
            "399/399 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9782\n",
            "Epoch 6: val_loss did not improve from 0.19909\n",
            "399/399 [==============================] - 280s 702ms/step - loss: 0.0635 - accuracy: 0.9782 - val_loss: 0.5155 - val_accuracy: 0.8709\n",
            "Epoch 7/12\n",
            "399/399 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9827\n",
            "Epoch 7: val_loss did not improve from 0.19909\n",
            "399/399 [==============================] - 281s 705ms/step - loss: 0.0506 - accuracy: 0.9827 - val_loss: 6.1554 - val_accuracy: 0.3925\n",
            "Epoch 8/12\n",
            "399/399 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9848\n",
            "Epoch 8: val_loss did not improve from 0.19909\n",
            "399/399 [==============================] - 283s 711ms/step - loss: 0.0459 - accuracy: 0.9848 - val_loss: 0.3261 - val_accuracy: 0.9130\n",
            "Epoch 9/12\n",
            "399/399 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.9862\n",
            "Epoch 9: val_loss did not improve from 0.19909\n",
            "399/399 [==============================] - 278s 698ms/step - loss: 0.0420 - accuracy: 0.9862 - val_loss: 0.5424 - val_accuracy: 0.8763\n",
            "Epoch 10/12\n",
            "399/399 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9845\n",
            "Epoch 10: val_loss did not improve from 0.19909\n",
            "399/399 [==============================] - 283s 709ms/step - loss: 0.0465 - accuracy: 0.9845 - val_loss: 0.3274 - val_accuracy: 0.9187\n",
            "Epoch 11/12\n",
            "399/399 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9887\n",
            "Epoch 11: val_loss did not improve from 0.19909\n",
            "399/399 [==============================] - 283s 708ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 0.3619 - val_accuracy: 0.9120\n",
            "Epoch 12/12\n",
            "399/399 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9855\n",
            "Epoch 12: val_loss did not improve from 0.19909\n",
            "399/399 [==============================] - 289s 726ms/step - loss: 0.0430 - accuracy: 0.9855 - val_loss: 0.3924 - val_accuracy: 0.9083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gmYx9f9MbIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a8015d-c5e9-4974-9ff1-8d217de62572"
      },
      "source": [
        "from tensorflow import keras\n",
        "keras.models.save_model(model, \"model.h5\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-02912c4d4e96>:2: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  keras.models.save_model(model, \"model.h5\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9jgf_nrjVDBk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5XK_aORMqql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a06dcb-5b9a-4d2b-b879-44ce94244990"
      },
      "source": [
        "model = tf.keras.models.load_model('/content/abc.h5')\n",
        "model.evaluate(val_generator)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101/101 [==============================] - 47s 464ms/step - loss: 0.1993 - accuracy: 0.9382\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1993241161108017, 0.9381877779960632]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok7IkLqhNmdl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f819f1b-a843-4202-a7a5-bef4f222de35"
      },
      "source": [
        "\n",
        "test_images = [f for f in os.listdir('/content/output/val')]\n",
        "dataset = np.ndarray(shape=(len(test_images), 200, 200, 3))\n",
        "\n",
        "import cv2\n",
        "\n",
        "for i, file_name in enumerate(test_images):\n",
        "  try:\n",
        "    img=cv2.imread('/content/output/val' + file_name)\n",
        "    img_resize=cv2.resize(img,(200,200))\n",
        "    dataset[i]=np.array(img_resize)/255.0\n",
        "  except:\n",
        "    print(file_name)\n",
        "dataset.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Strawberry___Leaf_scorch\n",
            "Tomato___Septoria_leaf_spot\n",
            "Pepper,_bell___Bacterial_spot\n",
            "Apple___Black_rot\n",
            "Tomato___Early_blight\n",
            "Tomato___Target_Spot\n",
            "Grape___Esca_(Black_Measles)\n",
            "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
            "Tomato___healthy\n",
            "Grape___healthy\n",
            "Pepper,_bell___healthy\n",
            "Cherry_(including_sour)___Powdery_mildew\n",
            "Peach___Bacterial_spot\n",
            "Apple___Apple_scab\n",
            "Cherry_(including_sour)___healthy\n",
            "Tomato___Tomato_mosaic_virus\n",
            "Peach___healthy\n",
            "Potato___Late_blight\n",
            "Potato___healthy\n",
            "Soybean___healthy\n",
            "Tomato___Late_blight\n",
            "Strawberry___healthy\n",
            "Squash___Powdery_mildew\n",
            "Potato___Early_blight\n",
            "Tomato___Spider_mites Two-spotted_spider_mite\n",
            "Blueberry___healthy\n",
            "Orange___Haunglongbing_(Citrus_greening)\n",
            "Tomato___Bacterial_spot\n",
            "Healthy_leaf\n",
            "Grape___Black_rot\n",
            "Tomato___Leaf_Mold\n",
            "Raspberry___healthy\n",
            "Apple___Cedar_apple_rust\n",
            "Apple___healthy\n",
            "Tomato___Tomato_Yellow_Leaf_Curl_Virus\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35, 200, 200, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6ugfrwZoaiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09bfdb6-7840-42b3-fe83-a729f658a248"
      },
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model('/content/model.h5')\n",
        "## For TFLite model\n",
        "converter=tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model=converter.convert()\n",
        "open('model.tflite', 'wb').write(tflite_model)\n",
        "## For TFLite optimized model\n",
        "converter.optimizations=[tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_opt_model=converter.convert()\n",
        "open('model_opt.tflite', 'wb').write(tflite_opt_model)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "249024"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWE0Vkoiu8Wy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a2f9cac7-a420-4135-8a64-a7ed2c5957ae"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('model.h5')  ##generated model file\n",
        "files.download('model.tflite') ##generated model tflite converted file\n",
        "files.download('model_opt.tflite') ##generated model tflite converted file"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0f78bccc-3eb0-4ef9-9712-c0f1edaf94e0\", \"model.h5\", 2916312)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8e447397-6772-46b5-bc12-9a1e2a87a057\", \"model.tflite\", 943084)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_945392ab-eb57-496d-8ad0-2245262a32aa\", \"model_opt.tflite\", 249024)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\n",
        "    \"Pepper,_bell___Bacterial_spot\",\n",
        "    \"Apple___Black_rot\",\n",
        "    \"Peach___healthy\",\n",
        "    \"Strawberry___Leaf_scorch\",\n",
        "    \"Grape___healthy\",\n",
        "    \"Apple___Cedar_apple_rust\",\n",
        "    \"Orange___Haunglongbing_(Citrus_greening)\",\n",
        "    \"Blueberry___healthy\",\n",
        "    \"Grape___Black_rot\",\n",
        "    \"Potato___Early_blight\",\n",
        "    \"Cherry_(including_sour)___Powdery_mildew\",\n",
        "    \"Cherry_(including_sour)___healthy\",\n",
        "    \"Grape___Esca_(Black_Measles)\",\n",
        "    \"Potato___healthy\",\n",
        "    \"Healthy_leaf\",\n",
        "    \"Tomato___Leaf_Mold\",\n",
        "    \"Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\",\n",
        "    \"Tomato___Tomato_mosaic_virus\",\n",
        "    \"Tomato___healthy\",\n",
        "    \"Apple___Apple_scab\",\n",
        "    \"Tomato___Target_Spot\",\n",
        "    \"Tomato___Septoria_leaf_spot\",\n",
        "    \"Peach___Bacterial_spot\",\n",
        "    \"Tomato___Spider_mites Two-spotted_spider_mite\",\n",
        "    \"Tomato___Bacterial_spot\",\n",
        "    \"Strawberry___healthy\",\n",
        "    \"Tomato___Early_blight\",\n",
        "    \"Tomato___Late_blight\",\n",
        "    \"Apple___healthy\",\n",
        "    \"Pepper,_bell___healthy\",\n",
        "    \"Raspberry___healthy\",\n",
        "    \"Squash___Powdery_mildew\",\n",
        "    \"Soybean___healthy\",\n",
        "    \"Tomato___Tomato_Yellow_Leaf_Curl_Virus\",\n",
        "    \"Potato___Late_blight\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "2v8NrKALmzti"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def load_and_preprocess_image(file_path):\n",
        "    # Load image using OpenCV\n",
        "    img = cv2.imread(file_path)\n",
        "    # Resize image to match model input shape (200x200 pixels)\n",
        "    img_resized = cv2.resize(img, (200, 200))\n",
        "    # Convert pixel values to float and normalize (assuming RGB image)\n",
        "    img_processed = img_resized.astype(np.float32) / 255.0\n",
        "    # Expand dimensions to match the input shape expected by the model\n",
        "    img_processed = np.expand_dims(img_processed, axis=0)\n",
        "    return img_processed\n",
        "\n",
        "# Example usage for loading a single image\n",
        "image_path = '/content/output/val/Grape___Esca_(Black_Measles)/0075b632-2e34-4e4f-9697-fe2b332b7ef8___FAM_B.Msls 4399.JPG'\n",
        "test_image = load_and_preprocess_image(image_path)\n"
      ],
      "metadata": {
        "id": "bedtbwz7lJx8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities for the image\n",
        "predictions = model.predict(test_image)\n",
        "\n",
        "# Decode the predictions (if needed)\n",
        "predicted_class = np.argmax(predictions, axis=-1)\n",
        "\n",
        "print(\"Predicted class:\", predicted_class)\n",
        "print(\"Predicted probabilities:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsdKFU3embEh",
        "outputId": "3fcbb62d-3001-4866-f916-2bf1ee4b99bd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Predicted class: [26]\n",
            "Predicted probabilities: [[2.0354126e-11 5.6343719e-10 2.9204395e-07 8.3364982e-11 5.9292637e-13\n",
            "  1.2715497e-10 5.1424307e-17 8.0752559e-04 3.9367063e-04 1.7712640e-14\n",
            "  4.7571738e-15 3.4492245e-18 4.3027357e-22 7.7792856e-13 1.3583039e-13\n",
            "  8.2791517e-11 1.2204480e-06 1.1430353e-06 2.2685511e-14 4.0000123e-06\n",
            "  1.6394799e-14 2.2607449e-11 1.1475616e-19 1.9065196e-13 4.8401750e-20\n",
            "  1.0359667e-15 9.9878329e-01 4.8760613e-09 3.6257991e-06 7.0817741e-08\n",
            "  1.2491417e-09 5.1764296e-06 1.0600128e-14 1.0795280e-08 1.0613495e-11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names[16]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Yb2b5MFWmeHj",
        "outputId": "f8f4a2f7-06aa-4a1a-9421-2a46e5105051"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "while True:\n",
        "    print(\"Keeping the kernel alive...\")\n",
        "    time.sleep(600)  # Sleep for 5 minutes (300 seconds)"
      ],
      "metadata": {
        "id": "i6ODc4j9m-FG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91892766-8175-49a8-c49d-d36f8277ffe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keeping the kernel alive...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEWkC12FW5Tw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}